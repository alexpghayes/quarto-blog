@article{berrett2021a,
  title = {Optimal Rates for Independence Testing via {{U-statistic}} Permutation Tests},
  author = {Berrett, Thomas B. and Kontoyiannis, Ioannis and Samworth, Richard J.},
  year = {2021},
  month = oct,
  journal = {The Annals of Statistics},
  volume = {49},
  number = {5},
  pages = {2457--2490},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/20-AOS2041},
  url = {https://www.projecteuclid.org/journals/annals-of-statistics/volume-49/issue-5/Optimal-rates-for-independence-testing-via-U-statistic-permutation-tests/10.1214/20-AOS2041.full},
  urldate = {2025-06-23},
  abstract = {We study the problem of independence testing given independent and identically distributed pairs taking values in a {$\sigma$}-finite, separable measure space. Defining a natural measure of dependence D(f) as the squared L2-distance between a joint density f and the product of its marginals, we first show that there is no valid test of independence that is uniformly consistent against alternatives of the form \{f:D(f){$\geq\rho$}2\}. We therefore restrict attention to alternatives that impose additional Sobolev-type smoothness constraints, and define a permutation test based on a basis expansion and a U-statistic estimator of D(f) that we prove is minimax optimal in terms of its separation rates in many instances. Finally, for the case of a Fourier basis on [0,1]2, we provide an approximation to the power function that offers several additional insights. Our methodology is implemented in the R package USP.},
  keywords = {62G09,62G10,Independence testing,minimax separation rates,permutation tests,Stein's method,U-statistics},
  file = {/home/alex/Zotero/storage/4K6484JS/Berrett et al. - 2021 - Optimal rates for independence testing via U-statistic permutation tests.pdf}
}

@article{breiman2001,
  title = {Statistical {{Modeling}}: {{The Two Cultures}}},
  shorttitle = {Statistical {{Modeling}}},
  author = {Breiman, Leo},
  year = {2001},
  month = aug,
  journal = {Statistical Science},
  volume = {16},
  number = {3},
  pages = {199--231},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/ss/1009213726},
  url = {https://projecteuclid.org/euclid.ss/1009213726},
  urldate = {2018-10-16},
  abstract = {There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.},
  langid = {english},
  mrnumber = {MR1874152},
  zmnumber = {1059.62505},
  file = {/home/alex/Zotero/storage/W34HEPZI/Breiman - 2001 - Statistical Modeling The Two Cultures.pdf;/home/alex/Zotero/storage/XAPBS7IM/1009213726.html}
}

@article{chen2020,
  title = {Targeted Sampling from Massive Block Model Graphs with Personalized {{PageRank}}},
  author = {Chen, Fan and Zhang, Yini and Rohe, Karl},
  year = {2020},
  month = feb,
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume = {82},
  number = {1},
  pages = {99--126},
  issn = {13697412},
  doi = {10.1111/rssb.12349},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/rssb.12349},
  urldate = {2021-08-10},
  abstract = {The paper provides statistical theory and intuition for personalized PageRank (called `PPR'): a popular technique that samples a small community from a massive network.We study a setting where the entire network is expensive to obtain thoroughly or to maintain, but we can start from a seed node of interest and `crawl' the network to find other nodes through their connections. By crawling the graph in a designed way, the PPR vector can be approximated without querying the entire massive graph, making it an alternative to snowball sampling. Using the degreecorrected stochastic block model, we study whether the PPR vector can select nodes that belong to the same block as the seed node. We provide a simple and interpretable form for the PPR vector, highlighting its biases towards high degree nodes outside the target block. We examine a simple adjustment based on node degrees and establish consistency results for PPR clustering that allows for directed graphs. These results are enabled by recent technical advances showing the elementwise convergence of eigenvectors. We illustrate the method with the massive Twitter friendship graph, which we crawl by using the Twitter application programming interface. We find that the adjusted and unadjusted PPR techniques are complementary approaches, where the adjustment makes the results particularly localized around the seed node, and that the bias adjustment greatly benefits from degree regularization.},
  langid = {english},
  file = {/home/alex/Zotero/storage/64MT3UQ6/Chen et al. - 2020 - Targeted sampling from massive block model graphs .pdf}
}

@article{dunson2009,
  title = {Nonparametric {{Bayes}} Local Partition Models for Random Effects},
  author = {Dunson, David B.},
  year = {2009},
  month = jun,
  journal = {Biometrika},
  volume = {96},
  number = {2},
  pages = {249--262},
  issn = {0006-3444},
  doi = {10.1093/biomet/asp021},
  url = {https://doi.org/10.1093/biomet/asp021},
  urldate = {2024-08-06},
  abstract = {This paper focuses on the problem of choosing a prior for an unknown random effects distribution within a Bayesian hierarchical model. The goal is to obtain a sparse representation by allowing a combination of global and local borrowing of information. A local partition process prior is proposed, which induces dependent local clustering. Subjects can be clustered together for a subset of their parameters, and one learns about similarities between subjects increasingly as parameters are added. Some basic properties are described, including simple two-parameter expressions for marginal and conditional clustering probabilities. A slice sampler is developed which bypasses the need to approximate the countably infinite random measure in performing posterior computation. The methods are illustrated using simulation examples, and an application to hormone trajectory data.},
  file = {/home/alex/Zotero/storage/KLEGR6SJ/Dunson - 2009 - Nonparametric Bayes local partition models for ran.pdf;/home/alex/Zotero/storage/4V6R3D5E/249850.html}
}

@book{efron2021,
  title = {Computer {{Age Statistical Inference}}, {{Student Edition}}: {{Algorithms}}, {{Evidence}}, and {{Data Science}}},
  shorttitle = {Computer {{Age Statistical Inference}}, {{Student Edition}}},
  author = {Efron, Bradley},
  year = {2021},
  series = {Institute of {{Mathematical Statistics Monographs}}},
  edition = {1st ed},
  number = {v.Series Number 6},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  collaborator = {Hastie, Trevor},
  isbn = {978-1-108-82341-8 978-1-108-91587-8},
  langid = {english},
  file = {/home/alex/Zotero/storage/FK37P96X/Efron and Hastie - Computer Age Statistical Inference.pdf}
}

@article{gelman2020,
  title = {What Are the Most Important Statistical Ideas of the Past 50 Years?},
  author = {Gelman, Andrew and Vehtari, Aki},
  year = {2020},
  month = nov,
  journal = {arXiv:2012.00174 [stat]},
  eprint = {2012.00174},
  primaryclass = {stat},
  url = {http://arxiv.org/abs/2012.00174},
  urldate = {2020-12-03},
  abstract = {We argue that the most important statistical ideas of the past half century are: counterfactual causal inference, bootstrapping and simulation-based inference, overparameterized models and regularization, multilevel models, generic computation algorithms, adaptive decision analysis, robust inference, and exploratory data analysis. We discuss common features of these ideas, how they relate to modern computing and big data, and how they might be developed and extended in future decades. The goal of this article is to provoke thought and discussion regarding the larger themes of research in statistics and data science.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/alex/Zotero/storage/RJQRCPFH/Gelman and Vehtari - 2020 - What are the most important statistical ideas of t.pdf}
}

@article{hayes2025a,
  title = {Co-{{Factor Analysis}} of {{Citation Networks}}},
  author = {Hayes, Alex and {and Rohe}, Karl},
  year = {2025},
  month = apr,
  journal = {Journal of Computational and Graphical Statistics},
  volume = {34},
  number = {2},
  pages = {448--461},
  publisher = {ASA Website},
  issn = {1061-8600},
  doi = {10.1080/10618600.2024.2394464},
  url = {https://doi.org/10.1080/10618600.2024.2394464},
  urldate = {2025-06-03},
  abstract = {One compelling use of citation networks is to characterize papers by their relationships to the surrounding literature. We propose a method to characterize papers by embedding them into two distinct ``co-factor'' spaces: one describing how papers send citations, and the other describing how papers receive citations. This approach presents several challenges. First, older documents cannot cite newer documents, and thus it is not clear that co-factors are even identifiable. We resolve this challenge by developing a co-factor model for asymmetric adjacency matrices with missing lower triangles and showing that identification is possible. We then frame estimation as a matrix completion problem and develop a specialized implementation of matrix completion because prior implementations are memory bound in our setting. Simulations show that our estimator has promising finite sample properties, and that naive approaches fail to recover latent co-factor structure. We leverage our estimator to investigate 255,780 papers published in statistics journals from 1898 to 2024, resulting in the most comprehensive topic model of the statistics literature to date. We find interpretable co-factors corresponding to many statistical subfields, including time series, variable selection, spatial methods, graphical models, GLM(M)s, causal inference, multiple testing, quantile regression, semiparametrics, dimension reduction, and several more. Supplementary materials for this article are available online.},
  keywords = {Co-factor models,Matrix completion,Missing data,Spectral network analysis,Stochastic blockmodels},
  file = {/home/alex/Zotero/storage/5ES6XYFJ/Hayes and and Rohe - 2025 - Co-Factor Analysis of Citation Networks.pdf}
}

@article{hicks2019,
  title = {Elements and {{Principles}} of {{Data Analysis}}},
  author = {Hicks, Stephanie C. and Peng, Roger D.},
  year = {2019},
  month = mar,
  journal = {arXiv:1903.07639 [stat]},
  eprint = {1903.07639},
  primaryclass = {stat},
  url = {http://arxiv.org/abs/1903.07639},
  urldate = {2019-03-25},
  abstract = {The data revolution has led to an increased interest in the practice of data analysis. As a result, there has been a proliferation of ``data science'' training programs. Because data science has been previously defined as an intersection of already-established fields or union of emerging technologies, the following problems arise: (1) There is little agreement about what is data science; (2) Data science becomes secondary to established fields in a university setting; and (3) It is difficult to have discussions on what it means to learn about data science, to teach data science courses and to be a data scientist. To address these problems, we propose to define the field from first principles based on the activities of people who analyze data with a language and taxonomy for describing a data analysis in a manner spanning disciplines. Here, we describe the elements and principles of data analysis. This leads to two insights: it suggests a formal mechanism to evaluate data analyses based on objective characteristics, and it provides a framework to teach students how to build data analyses. We argue that the elements and principles of data analysis lay the foundational framework for a more general theory of data science.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {/home/alex/Zotero/storage/MFR7H7PZ/Hicks and Peng - 2019 - Elements and Principles of Data Analysis.pdf}
}

@article{neal2003,
  title = {Slice Sampling},
  author = {Neal, Radford M.},
  year = {2003},
  month = jun,
  journal = {The Annals of Statistics},
  volume = {31},
  number = {3},
  pages = {705--767},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/aos/1056562461},
  url = {https://projecteuclid.org/journals/annals-of-statistics/volume-31/issue-3/Slice-sampling/10.1214/aos/1056562461.full},
  urldate = {2025-06-23},
  abstract = {Markov chain sampling methods that adapt to characteristics of the distribution being sampled can be constructed using the principle that one can ample from a distribution by sampling uniformly from the region under the plot of its density function. A Markov chain that converges to this uniform distribution can be constructed by alternating uniform sampling in the vertical direction with uniform sampling from the horizontal "slice" defined by the current vertical position, or more generally, with some update that leaves the uniform distribution over this slice invariant. Such "slice sampling" methods are easily implemented for univariate distributions, and can be used to sample from a multivariate distribution by updating each variable in turn. This approach is often easier to implement than Gibbs sampling and more efficient than simple Metropolis updates, due to the ability of slice sampling to adaptively choose the magnitude of changes made. It is therefore attractive for routine and automated use. Slice sampling methods that update all variables simultaneously are also possible. These methods can adaptively choose the magnitudes of changes made to each variable, based on the local properties of the density function. More ambitiously, such methods could potentially adapt to the dependencies between variables by constructing local quadratic approximations. Another approach is to improve sampling efficiency by suppressing random walks. This can be done for univariate slice sampling by "overrelaxation," and for multivariate slice sampling by "reflection" from the edges of the slice.},
  keywords = {65C05,65C60,Adaptive methods,auxiliary variables,dynamical methods,Gibbs sampling,Markov chain Monte Carlo,Metropolis algorithm,overrelaxation},
  file = {/home/alex/Zotero/storage/H68C8QGS/Neal - 2003 - Slice sampling.pdf}
}

@article{qing2021,
  title = {Directed Mixed Membership Stochastic Blockmodel},
  author = {Qing, Huan and Wang, Jingli},
  year = {2021},
  month = oct,
  journal = {arXiv:2101.02307 [cs, stat]},
  eprint = {2101.02307},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/2101.02307},
  urldate = {2022-02-08},
  abstract = {Mixed membership problem for undirected network has been well studied in network analysis recent years. However, the more general case of mixed membership for directed network remains a challenge. Here, we propose an interpretable and identifiable model: directed mixed membership stochastic blockmodel (DiMMSB for short) for directed mixed membership networks. DiMMSB allows that row nodes and column nodes of the adjacency matrix can be different and these nodes may have distinct community structure in a directed network. We also develop an efficient spectral algorithm called DiSP designed based on simplex structures inherent in the left and right singular vectors of the population adjacency matrix to estimate the mixed memberships for both row nodes and column nodes in a directed network. We show that DiSP is asymptotically consistent under mild conditions by providing error bounds for the inferred membership vectors of each row node and each column node using delicate spectral analysis. We demonstrate the advantages of DiSP with applications to simulated directed mixed membership network, the directed Political blogs network and the Papers Citation network.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  file = {/home/alex/Zotero/storage/BUIHGMIP/Qing and Wang - 2021 - Directed mixed membership stochastic blockmodel.pdf}
}

@misc{qing2022,
  title = {Directed Mixed Membership Stochastic Blockmodel},
  author = {Qing, Huan and Wang, Jingli},
  year = {2022},
  month = sep,
  number = {arXiv:2101.02307},
  eprint = {2101.02307},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2101.02307},
  urldate = {2024-10-03},
  abstract = {Mixed membership problem for undirected network has been well studied in network analysis recent years. However, the more general case of mixed membership for directed network in which nodes can belong to multiple communities remains a challenge. Here, we propose an interpretable and identifiable model: directed mixed membership stochastic blockmodel (DiMMSB) for directed mixed membership networks. DiMMSB allows that row nodes and column nodes of the adjacency matrix can be different and these nodes may have distinct community structure in a directed network. We also develop an efficient spectral algorithm called DiSP designed based on simplex structures inherent in the left and right singular vectors of the population adjacency matrix to estimate the mixed memberships for both row nodes and column nodes in a directed network. We show that DiSP is asymptotically consistent under mild conditions by providing error bounds for the inferred membership vectors of each row node and each column node using delicate spectral analysis. Numerical results on computer-generated directed mixed membership networks support our theoretical findings and show that our DiSP outperforms its competitor in both error rates and run-time. Applications of DiSP to real-world directed networks demonstrate the advantages of DiSP in studying the asymmetric structure of directed networks.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  file = {/home/alex/Zotero/storage/9YTXL5JX/Qing and Wang - 2022 - Directed mixed membership stochastic blockmodel.pdf}
}

@book{shapin1994,
  title = {A Social History of Truth: Civility and Science in Seventeenth-Century {{England}}},
  shorttitle = {A Social History of Truth},
  author = {Shapin, Steven},
  year = {1994},
  series = {Science and Its Conceptual Foundations},
  publisher = {University of Chicago Press},
  address = {Chicago},
  isbn = {978-0-226-75018-7},
  langid = {english},
  lccn = {Q175.52.G7 S48 1994},
  keywords = {17th century,England,Moral and ethical aspects History,Science,Social aspects History},
  file = {/home/alex/Zotero/storage/7ZJLWCF4/Shapin - 1994 - A social history of truth civility and science in.pdf}
}

@article{tukey1962,
  title = {The {{Future}} of {{Data Analysis}}},
  author = {Tukey, John W.},
  year = {1962},
  journal = {The annals of mathematical statistics},
  file = {/home/alex/Zotero/storage/ZD9M7HKB/euclid.aoms.1177704711.pdf}
}
