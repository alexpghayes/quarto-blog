@article{flanigan2021a,
  title = {Supplementary Information: {{Fair}} Algorithms for Selecting Citizens' Assemblies},
  author = {Flanigan, Bailey and G{\"o}lz, Paul and Gupta, Anupam and Hennig, Brett and Procaccia, Ariel D.},
  year = {2021},
  month = aug,
  journal = {Nature},
  volume = {596},
  number = {7873},
  pages = {548--552},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/s41586-021-03788-6},
  urldate = {2024-06-25},
  abstract = {Abstract                            Globally, there has been a recent surge in `citizens' assemblies'               1               , which are a form of civic participation in which a panel of randomly selected constituents contributes to questions of policy. The random process for selecting this panel should satisfy two properties. First, it must produce a panel that is representative of the population. Second, in the spirit of democratic equality, individuals would ideally be selected to serve on this panel with equal probability               2,3               . However, in practice these desiderata are in tension owing to differential participation rates across subpopulations               4,5               . Here we apply ideas from fair division to develop selection algorithms that satisfy the two desiderata simultaneously to the greatest possible extent: our selection algorithms choose representative panels while selecting individuals with probabilities as close to equal as mathematically possible, for many metrics of `closeness to equality'. Our implementation of one such algorithm has already been used to select more than 40~citizens' assemblies around the world. As we demonstrate using data from ten citizens' assemblies, adopting our algorithm over a benchmark representing the previous state of the art leads to substantially fairer selection probabilities. By contributing a fairer, more principled and deployable algorithm, our work puts the practice of sortition on firmer foundations. Moreover, our work establishes citizens' assemblies as a domain in which insights from the field of fair division can lead to high-impact applications.},
  langid = {english},
  file = {/home/alex/Zotero/storage/9QUPQ2NY/Flanigan et al. - 2021 - Fair algorithms for selecting citizensâ€™ assemblies.pdf}
}

@inproceedings{karimi2017,
  title = {Stochastic {{Submodular Maximization}}: {{The Case}} of {{Coverage Functions}}},
  booktitle = {31st {{Conference}} on {{Neural Information Processing Systems}}},
  author = {Karimi, Mohammad and Lucic, Mario and Hassani, Hamed and Krause, Andreas},
  year = {2017},
  abstract = {Stochastic optimization of continuous objectives is at the heart of modern machine learning. However, many important problems are of discrete nature and often involve submodular objectives. We seek to unleash the power of stochastic continuous optimization, namely stochastic gradient descent and its variants, to such discrete problems. We first introduce the problem of stochastic submodular optimization, where one needs to optimize a submodular objective which is given as an expectation. Our model captures situations where the discrete objective arises as an empirical risk (e.g., in the case of exemplar-based clustering), or is given as an explicit stochastic model (e.g., in the case of influence maximization in social networks). By exploiting that common extensions act linearly on the class of submodular functions, we employ projected stochastic gradient ascent and its variants in the continuous domain, and perform rounding to obtain discrete solutions. We focus on the rich and widely used family of weighted coverage functions. We show that our approach yields solutions that are guaranteed to match the optimal approximation guarantees, while reducing the computational cost by several orders of magnitude, as we demonstrate empirically.},
  langid = {english},
  file = {/home/alex/Zotero/storage/MBAGLR4G/Karimi et al. - Stochastic Submodular Maximization The Case of Co.pdf}
}

@misc{karimi2017a,
  title = {Stochastic {{Submodular Maximization}}: {{The Case}} of {{Coverage Functions}}},
  shorttitle = {Stochastic {{Submodular Maximization}}},
  author = {Karimi, Mohammad Reza and Lucic, Mario and Hassani, Hamed and Krause, Andreas},
  year = {2017},
  month = nov,
  number = {arXiv:1711.01566},
  eprint = {1711.01566},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2024-06-25},
  abstract = {Stochastic optimization of continuous objectives is at the heart of modern machine learning. However, many important problems are of discrete nature and often involve submodular objectives. We seek to unleash the power of stochastic continuous optimization, namely stochastic gradient descent and its variants, to such discrete problems. We first introduce the problem of stochastic submodular optimization, where one needs to optimize a submodular objective which is given as an expectation. Our model captures situations where the discrete objective arises as an empirical risk (e.g., in the case of exemplar-based clustering), or is given as an explicit stochastic model (e.g., in the case of influence maximization in social networks). By exploiting that common extensions act linearly on the class of submodular functions, we employ projected stochastic gradient ascent and its variants in the continuous domain, and perform rounding to obtain discrete solutions. We focus on the rich and widely used family of weighted coverage functions. We show that our approach yields solutions that are guaranteed to match the optimal approximation guarantees, while reducing the computational cost by several orders of magnitude, as we demonstrate empirically.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Discrete Mathematics,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/alex/Zotero/storage/X2KF7QWB/Karimi et al. - 2017 - Stochastic Submodular Maximization The Case of Co.pdf}
}
