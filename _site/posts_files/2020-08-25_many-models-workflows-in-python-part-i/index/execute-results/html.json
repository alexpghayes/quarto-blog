{
  "hash": "927d5951d7e854aae71408c4ddbc3ade",
  "result": {
    "markdown": "---\ntitle: 'many models workflows in python: part i'\nsubtitle: |\n  python modeling with list columns \ndate: '2020-08-25'\n---\n\nThis summer I worked on my first substantial research project in Python. I've used Python for a number of small projects before, but this was the first time that it was important for me to have an efficient workflow for working with many models at once. In R, I spend almost all of my time using a 'many models' workflow that leverages list-columns in `tibble`s and a hefty amount of `tidyverse` manipulation. It's taken me a while to find a similar workflow in Python that I like, and so I'm documenting it here for myself and other parties who might benefit.\n\nThis post demonstrates how to organize models into dataframes for exploratory data analysis, and discusses why you might want to do this. In a future blog post I will show how to extend the basic workflow I present here to handle sample splitting, custom estimators, and parallel processing.\n\n## Interlude for Pythonistas: many models workflows\n\nThe many models workflow is an extension of the 'split-apply-combine' workflow, a largely functional approach to data manipulation implemented in `dplyr` and `pandas`. The essential ideas of 'split-apply-combine' are articulated nicely in Hadley Wickham's short and easy to read [paper](https://www.jstatsoft.org/article/view/v040i01/v40i01.pdf), which I strongly encourage you to read. I assume you are comfortable with this general idea, which largely facilitates natural ways to compute descriptive statistics from data, and have some experience applying these concepts in either `dplyr`, `pandas`, or SQL.\n\nSeveral years ago, this idea evolved: what if, instead of computing descriptive statistics, we wanted to compute more complicated estimands, while leveraging the power of grouped operations? Hadley's solution, which has proven very fruitful and served as the underlying idea for `tidymodels`, `tidyverts`, and several other modeling frameworks, is to put model objects themselves into dataframes. Hadley [presented](https://www.youtube.com/watch?v=rz3_FDVt9eg) on this idea, and also wrote about it in the [many models chapter](https://r4ds.had.co.nz/many-models.html) of *R for Data Science* and it has turned out to be quite fruitful.\n\n## Why is putting model objects in dataframes a good idea?\n\nThe simple answer is that it keeps information about your models from drifting apart, as it tends to do otherwise.\n\nMy exploratory modeling often ends up looking something like this:\n\n-   I want to compare models across a range of hyperparameter values. Often there are several distinct hyperparameters to consider at once[^1].\n\n-   I want to look at many different properties of the model. As a contrived example, I might want to look at AIC, BIC, $R^2$ and RMSE for all my models[^2].\n\n-   I want to quick create plots to compare these models, and am probably using a plotting libraries expects data in data frames\n\n[^1]: It often makes sense to store hyperparameters in dicts in Python. This means you can't easily store model objects in dicts, because `model_store[hyperparameters] = my_model_object` gets all fussy because the hyperparameter dictionary isn't hashable.\n\n[^2]: One natural approach here would be to have a list of model objects, a list of AIC values, a list of BIC values, etc. Now you run into an indexing issue where you have to figure out which index corresponds to a given model and keeping track of a bunch of maps like this. A natural solution is to say force all the indexes to match up -- everything with index 0 should correspond to the first model. Congratulations, you've just invented a data frame.\n\nAnyway it turns out that dataframes handle this use case super well, provided we have some helpers. The overall workflow will look like this:\n\n1.  **Specifying models to fit**: We organize a dataframe so that each row of the dataframe corresponds to one model we want to fit. For example, a single row of the dataframe might correspond to a single set of hyperparameter values, or a subset of the data.\n\n2.  **Iterative model fitting**: We create a new column in the dataframes that holds fit models.\n\n3.  **Iterative estimate extraction**: We extract information we want from the fits into new data frame columns, and then manipulate this data with our favorite dataframe or plotting libraries.\n\nNote that steps (2) and (3) require iteration over many models. In functional languages, `map`-style operations are a natural (and easily parallelizable!) way to do this; in Python we can use list-comprehensions.\n\nAnother innovation in this workflow came from standardizing step (3), where we extract information from the models into a new column of the dataframe. A big issue that we can run into here is that when we extract information from the model object, it can have an inconvenient type that is hard to put in a dataframe column. This may seem esoteric but it turns out to matter a lot more than you'd expect.\n\nDavid Robinson in his `broom` package proposed a solution that is increasingly the standard within the R community[^3]. The idea is to create special getter methods for model objects that always return information in consistently formatted data frames. For each model object, we get a data frame with information. Since there are many model objects, we end up with a column of dataframes, which we then flatten.\n\n[^3]: I am currently the `broom` maintainer.\n\nThere has been a lot of pushback around the idea of a column of dataframes with the Python community, largely on the basis that it is not a performant data structure[^4]. This misses the point. The compute time in these workflows comes from model fitting, and afterwards we just want to keep track of things[^5].\n\n[^4]: Another big selling point of dataframes is vectorized operations on the columns. However, you can't vectorize operations on model objects, and this leads to code that has to perform vectorize explicitly rather than letting dataframe libraries handle it implicitly. There is a definitely a learning curve for new users here but I'm pretty convinced it's worth it.\n\n[^5]: Another complaint that you might have as a Pythonista is that you should construct a custom model object to handle all this model tracking. I'm actually pretty curious about this and would love to hear ideas. My suspition is that the big challenge is coming up with a sufficiently general framework to accommodate widely varying use cases.\n\nAnyway, there's a lot more to say about the workflow conceptually, but for now, it is time to show some code and see how things work in practice. For this post, I am going to recreate the analysis that Hadley does in his linked presentation above, which makes use of the [gapminder](https://pypi.org/project/gapminder/) data. The gapminder data consists of life expectancies for 142 counties, reported every 5 years from 1952 to 2007.\n\n## Setting the scene\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport statsmodels.formula.api as smf\n\n# you can download the gapminder csv file from my google drive\n# https://drive.google.com/file/d/1pAgIKdsZPwYteQ2rfq14WrUtS23Tg4Lu/\n\ngapminder = pd.read_csv('gapminder.csv')\ngapminder\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>continent</th>\n      <th>year</th>\n      <th>lifeExp</th>\n      <th>pop</th>\n      <th>gdpPercap</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Afghanistan</td>\n      <td>Asia</td>\n      <td>1952</td>\n      <td>28.801</td>\n      <td>8425333</td>\n      <td>779.445314</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Afghanistan</td>\n      <td>Asia</td>\n      <td>1957</td>\n      <td>30.332</td>\n      <td>9240934</td>\n      <td>820.853030</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Afghanistan</td>\n      <td>Asia</td>\n      <td>1962</td>\n      <td>31.997</td>\n      <td>10267083</td>\n      <td>853.100710</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Afghanistan</td>\n      <td>Asia</td>\n      <td>1967</td>\n      <td>34.020</td>\n      <td>11537966</td>\n      <td>836.197138</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Afghanistan</td>\n      <td>Asia</td>\n      <td>1972</td>\n      <td>36.088</td>\n      <td>13079460</td>\n      <td>739.981106</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1699</th>\n      <td>Zimbabwe</td>\n      <td>Africa</td>\n      <td>1987</td>\n      <td>62.351</td>\n      <td>9216418</td>\n      <td>706.157306</td>\n    </tr>\n    <tr>\n      <th>1700</th>\n      <td>Zimbabwe</td>\n      <td>Africa</td>\n      <td>1992</td>\n      <td>60.377</td>\n      <td>10704340</td>\n      <td>693.420786</td>\n    </tr>\n    <tr>\n      <th>1701</th>\n      <td>Zimbabwe</td>\n      <td>Africa</td>\n      <td>1997</td>\n      <td>46.809</td>\n      <td>11404948</td>\n      <td>792.449960</td>\n    </tr>\n    <tr>\n      <th>1702</th>\n      <td>Zimbabwe</td>\n      <td>Africa</td>\n      <td>2002</td>\n      <td>39.989</td>\n      <td>11926563</td>\n      <td>672.038623</td>\n    </tr>\n    <tr>\n      <th>1703</th>\n      <td>Zimbabwe</td>\n      <td>Africa</td>\n      <td>2007</td>\n      <td>43.487</td>\n      <td>12311143</td>\n      <td>469.709298</td>\n    </tr>\n  </tbody>\n</table>\n<p>1704 rows × 6 columns</p>\n</div>\n```\n:::\n:::\n\n\nTo get a feel for the data, lets plot the life expectancy of each country over time, facetting by continent[^6].\n\n[^6]: Aside: I have found plotting in Python to be a largely unpleasant experience. At this point, I've pretty much settled on `seaborn` as my go-to plotting library, and I use `sns.FacetGrid` for almost everything, even when I don't need facetting, because enough of my `ggplot2` intuition carries over that I can mostly get things done.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\np = sns.FacetGrid(\n    data=gapminder,\n    hue='continent',\n    col='continent',\n    col_wrap=2,\n    height=4,\n    aspect=16/9\n).map(plt.plot, 'year', 'lifeExp')\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-3-output-1.png){width=1355 height=1139}\n:::\n:::\n\n\n## Step 1: specifying models to fit\n\nFollowing Hadley's presentation, suppose we would like to summarize the trend for each country by fitting a linear regression to the data from each country. So we have a correspondence 1 model \\~ data from 1 country, and want to set up our data frame so that each row corresponds to data from a single country.\n\n`groupby()` plus a list-comprehension handles this nicely, leveraging the fact that `gapminder.groupby('country')` is an iterable. In R, you could also use `group_by()` for this step, or additionally `nest()` or `rowwise()`, two `tidyverse` specification abstractions.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nmodels = pd.DataFrame({\n    # this works because grouped dataframes in pandas are iterable\n    # and because you can pretty much treat series objects like\n    # they are lists\n    'data': [data for _, data in gapminder.groupby('country')],\n})\n\nmodels.index = [country for country, _ in gapminder.groupby('country')]\n\n# the downside of putting weird stuff into pandas dataframes is that\n# the dataframes print poorly\nmodels\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Afghanistan</th>\n      <td>country continent  year  lifeExp      ...</td>\n    </tr>\n    <tr>\n      <th>Albania</th>\n      <td>country continent  year  lifeExp      pop ...</td>\n    </tr>\n    <tr>\n      <th>Algeria</th>\n      <td>country continent  year  lifeExp       pop...</td>\n    </tr>\n    <tr>\n      <th>Angola</th>\n      <td>country continent  year  lifeExp       pop ...</td>\n    </tr>\n    <tr>\n      <th>Argentina</th>\n      <td>country continent  year  lifeExp       p...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Vietnam</th>\n      <td>country continent  year  lifeExp       p...</td>\n    </tr>\n    <tr>\n      <th>West Bank and Gaza</th>\n      <td>country continent  year  life...</td>\n    </tr>\n    <tr>\n      <th>Yemen, Rep.</th>\n      <td>country continent  year  lifeExp    ...</td>\n    </tr>\n    <tr>\n      <th>Zambia</th>\n      <td>country continent  year  lifeExp       po...</td>\n    </tr>\n    <tr>\n      <th>Zimbabwe</th>\n      <td>country continent  year  lifeExp       ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>142 rows × 1 columns</p>\n</div>\n```\n:::\n:::\n\n\n## Step 2: iterative model fitting\n\nNow we need to do the actual model fitting. My preferred approach is to use list-comprehensions.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndef country_model(df):\n    return smf.ols('lifeExp ~ year', data=df).fit()\n\nmodels['fit'] = [\n    country_model(data)\n    for _, data in gapminder.groupby('country')\n]\n```\n:::\n\n\nOne compelling advantage of this (effectively) functional approach to iteration over list-columns of models is that most of these computations are embarrassingly parallel, and map()-like operations are often very easy to parallelize.\n\nAn alternative approach here is to use `DataFrame.apply()`. However, I have found the `Series.apply()` and `DataFrame.apply()` methods to be hard to reason about when used together with list-columns, and so I recommend avoiding them.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# the pandas apply() approach\n\n# models = (\n#     gapminder\n#     .groupby('country')\n#     .apply(country_model)\n#     .to_frame(name='fit')\n# )\n```\n:::\n\n\n## Step 3: iterative information extraction\n\nNow that we've fit all of our models, we can extract information from them. Here I'll define some helper functions very much in the spirit of `broom`. When you don't own the model classes you're using, you pretty much have to write extractor functions to do this; see Michael Chow's excellent [blog post](https://mchow.com/posts/2020-02-24-single-dispatch-data-science/) showing how to handle this in an elegant way.\n\nEven if you do own the model objects you're using, I recommend extractor functions over class methods. This is because, during EDA, you typically fit some expensive models once, and then repeatedly investigate them--you can modify an extractor function and use it right away, but if you modify a method for a model class, you'll have to refit all the model objects. This leads to slow iteration.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# ripped directly from michael chow's blog post!!\n# go read his stuff it's very cool!\ndef tidy(fit):\n    from statsmodels.iolib.summary import summary_params_frame\n    tidied = summary_params_frame(fit).reset_index()\n    rename_cols = {\n        'index': 'term', 'coef': 'estimate', 'std err': 'std_err',\n        't': 'statistic', 'P>|t|': 'p_value',\n        'Conf. Int. Low': 'conf_int_low', 'Conf. Int. Upp.': 'conf_int_high'\n    }\n    \n    return tidied.rename(columns = rename_cols)\n\ndef glance(fit):\n    return pd.DataFrame({\n        'aic': fit.aic,\n        'bic': fit.bic,\n        'ess': fit.ess, # explained sum of squares\n        'centered_tss': fit.centered_tss,\n        'fvalue': fit.fvalue,\n        'f_pvalue': fit.f_pvalue,\n        'nobs': fit.nobs,\n        'rsquared': fit.rsquared,\n        'rsquared_adj': fit.rsquared_adj\n    }, index=[0])\n\n# note that augment() takes 2 inputs, whereas tidy() and glance() take 1\ndef augment(fit, data):\n    df = data.copy()\n    \n    if len(df) != fit.nobs:\n        raise ValueError(\"`data` does not have same number of observations as in training data.\")\n    \n    df['fitted'] = fit.fittedvalues\n    df['resid'] = fit.resid\n    return df\n```\n:::\n\n\nWe sanity check the helper functions by seeing if they work on a single model object before working with the entire list-column of models.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ntidy(models.fit[0])\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>term</th>\n      <th>estimate</th>\n      <th>std_err</th>\n      <th>statistic</th>\n      <th>p_value</th>\n      <th>conf_int_low</th>\n      <th>conf_int_high</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Intercept</td>\n      <td>-507.534272</td>\n      <td>40.484162</td>\n      <td>-12.536613</td>\n      <td>1.934055e-07</td>\n      <td>-597.738606</td>\n      <td>-417.329937</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>year</td>\n      <td>0.275329</td>\n      <td>0.020451</td>\n      <td>13.462890</td>\n      <td>9.835213e-08</td>\n      <td>0.229761</td>\n      <td>0.320896</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nglance(models.fit[0])\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aic</th>\n      <th>bic</th>\n      <th>ess</th>\n      <th>centered_tss</th>\n      <th>fvalue</th>\n      <th>f_pvalue</th>\n      <th>nobs</th>\n      <th>rsquared</th>\n      <th>rsquared_adj</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40.69387</td>\n      <td>41.663683</td>\n      <td>271.006011</td>\n      <td>285.958116</td>\n      <td>181.24941</td>\n      <td>9.835213e-08</td>\n      <td>12.0</td>\n      <td>0.947712</td>\n      <td>0.942483</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n`augment()` actually takes two inputs, where one input is the model object, and the other is the training data used to fit that model object.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\naugment(models.fit[0], models.data[0])\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>continent</th>\n      <th>year</th>\n      <th>lifeExp</th>\n      <th>pop</th>\n      <th>gdpPercap</th>\n      <th>fitted</th>\n      <th>resid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Afghanistan</td>\n      <td>Asia</td>\n      <td>1952</td>\n      <td>28.801</td>\n      <td>8425333</td>\n      <td>779.445314</td>\n      <td>29.907295</td>\n      <td>-1.106295</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Afghanistan</td>\n      <td>Asia</td>\n      <td>1957</td>\n      <td>30.332</td>\n      <td>9240934</td>\n      <td>820.853030</td>\n      <td>31.283938</td>\n      <td>-0.951938</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Afghanistan</td>\n      <td>Asia</td>\n      <td>1962</td>\n      <td>31.997</td>\n      <td>10267083</td>\n      <td>853.100710</td>\n      <td>32.660582</td>\n      <td>-0.663582</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Afghanistan</td>\n      <td>Asia</td>\n      <td>1967</td>\n      <td>34.020</td>\n      <td>11537966</td>\n      <td>836.197138</td>\n      <td>34.037225</td>\n      <td>-0.017225</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Afghanistan</td>\n      <td>Asia</td>\n      <td>1972</td>\n      <td>36.088</td>\n      <td>13079460</td>\n      <td>739.981106</td>\n      <td>35.413868</td>\n      <td>0.674132</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Afghanistan</td>\n      <td>Asia</td>\n      <td>1977</td>\n      <td>38.438</td>\n      <td>14880372</td>\n      <td>786.113360</td>\n      <td>36.790512</td>\n      <td>1.647488</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Afghanistan</td>\n      <td>Asia</td>\n      <td>1982</td>\n      <td>39.854</td>\n      <td>12881816</td>\n      <td>978.011439</td>\n      <td>38.167155</td>\n      <td>1.686845</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Afghanistan</td>\n      <td>Asia</td>\n      <td>1987</td>\n      <td>40.822</td>\n      <td>13867957</td>\n      <td>852.395945</td>\n      <td>39.543798</td>\n      <td>1.278202</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Afghanistan</td>\n      <td>Asia</td>\n      <td>1992</td>\n      <td>41.674</td>\n      <td>16317921</td>\n      <td>649.341395</td>\n      <td>40.920442</td>\n      <td>0.753558</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Afghanistan</td>\n      <td>Asia</td>\n      <td>1997</td>\n      <td>41.763</td>\n      <td>22227415</td>\n      <td>635.341351</td>\n      <td>42.297085</td>\n      <td>-0.534085</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Afghanistan</td>\n      <td>Asia</td>\n      <td>2002</td>\n      <td>42.129</td>\n      <td>25268405</td>\n      <td>726.734055</td>\n      <td>43.673728</td>\n      <td>-1.544728</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Afghanistan</td>\n      <td>Asia</td>\n      <td>2007</td>\n      <td>43.828</td>\n      <td>31889923</td>\n      <td>974.580338</td>\n      <td>45.050372</td>\n      <td>-1.222372</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNow we are ready to iterate over the list-column of models. Again, we leverage list-comprehensions. For `tidy()` and `glance()` these comprehension are straightforward, but for `augment()`, which will consume elements from two columns at once, we will need to do something a little fancier. In R we could use `purrr::map2()` or `purrr::pmap()`, but the Pythonic idiom here is to use `zip()` together with tuple unpacking.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nmodels['tidied'] = [tidy(fit) for fit in models.fit]\nmodels['glanced'] = [glance(fit) for fit in models.fit]\n\nmodels['augmented'] = [\n    augment(fit, data)\n    for fit, data in zip(models.fit, models.data)\n]\n```\n:::\n\n\n**Note for R users**: In R the calls to `tidy()`, etc, would typically live inside a `mutate()` call. The `pandas` equivalent is `assign`, but `pandas` doesn't leverage non-standard evaluation and I typically don't use `assign()` unless I really want to leverage method chaining for some reason. Normally I save method chaining for data manipulation once I have a flat dataframe, and otherwise I operate entirely via list comprehensions.\n\nAnyway, the print method garbles the hell out of our results but whatever.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nmodels\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>data</th>\n      <th>fit</th>\n      <th>tidied</th>\n      <th>glanced</th>\n      <th>augmented</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Afghanistan</th>\n      <td>country continent  year  lifeExp      ...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term    estimate    std_err  statistic...</td>\n      <td>aic        bic         ess  centered_t...</td>\n      <td>country continent  year  lifeExp      ...</td>\n    </tr>\n    <tr>\n      <th>Albania</th>\n      <td>country continent  year  lifeExp      pop ...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term    estimate    std_err  statistic...</td>\n      <td>aic        bic         ess  centered_...</td>\n      <td>country continent  year  lifeExp      pop ...</td>\n    </tr>\n    <tr>\n      <th>Algeria</th>\n      <td>country continent  year  lifeExp       pop...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term    estimate    std_err  statistic...</td>\n      <td>aic       bic          ess  centered_...</td>\n      <td>country continent  year  lifeExp       pop...</td>\n    </tr>\n    <tr>\n      <th>Angola</th>\n      <td>country continent  year  lifeExp       pop ...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term    estimate    std_err  statistic...</td>\n      <td>aic       bic         ess  centered_t...</td>\n      <td>country continent  year  lifeExp       pop ...</td>\n    </tr>\n    <tr>\n      <th>Argentina</th>\n      <td>country continent  year  lifeExp       p...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term    estimate   std_err  statistic ...</td>\n      <td>aic       bic         ess  centered_ts...</td>\n      <td>country continent  year  lifeExp       p...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Vietnam</th>\n      <td>country continent  year  lifeExp       p...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term     estimate    std_err  statisti...</td>\n      <td>aic        bic          ess  centered...</td>\n      <td>country continent  year  lifeExp       p...</td>\n    </tr>\n    <tr>\n      <th>West Bank and Gaza</th>\n      <td>country continent  year  life...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term     estimate    std_err  statisti...</td>\n      <td>aic       bic          ess  centered_...</td>\n      <td>country continent  year  life...</td>\n    </tr>\n    <tr>\n      <th>Yemen, Rep.</th>\n      <td>country continent  year  lifeExp    ...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term     estimate    std_err  statisti...</td>\n      <td>aic        bic          ess  centered...</td>\n      <td>country continent  year  lifeExp    ...</td>\n    </tr>\n    <tr>\n      <th>Zambia</th>\n      <td>country continent  year  lifeExp       po...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term    estimate     std_err  statisti...</td>\n      <td>aic        bic        ess  centered_t...</td>\n      <td>country continent  year  lifeExp       po...</td>\n    </tr>\n    <tr>\n      <th>Zimbabwe</th>\n      <td>country continent  year  lifeExp       ...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term    estimate     std_err  statisti...</td>\n      <td>aic       bic        ess  centered_ts...</td>\n      <td>country continent  year  lifeExp       ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>142 rows × 5 columns</p>\n</div>\n```\n:::\n:::\n\n\n## Flattening the dataframe\n\nOur final step before we can recreate Hadley's plots is to flatten or \"unnest\" the dataframe. `pandas` has no unnest method, but the following has served me well so far to unnest a single column. This will not play well with dataframes with MultiIndexes, which I recommend avoiding.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ndef unnest(df, value_col):\n    lst = df[value_col].tolist()\n    unnested = pd.concat(lst, keys=df.index)\n    unnested.index = unnested.index.droplevel(-1)\n    return df.join(unnested).drop(columns=value_col)\n```\n:::\n\n\nIf we unnest just the `glance()` results we get:\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nglance_results = unnest(models, 'glanced')\n\n# equivalently\nglance_results = (\n    models\n    .pipe(unnest, 'glanced')\n    \n    # little bit of extra cleanup\n    .reset_index()\n    .rename(columns={'index': 'country'})\n)\n\nglance_results\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>data</th>\n      <th>fit</th>\n      <th>tidied</th>\n      <th>augmented</th>\n      <th>aic</th>\n      <th>bic</th>\n      <th>ess</th>\n      <th>centered_tss</th>\n      <th>fvalue</th>\n      <th>f_pvalue</th>\n      <th>nobs</th>\n      <th>rsquared</th>\n      <th>rsquared_adj</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Afghanistan</td>\n      <td>country continent  year  lifeExp      ...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term    estimate    std_err  statistic...</td>\n      <td>country continent  year  lifeExp      ...</td>\n      <td>40.693870</td>\n      <td>41.663683</td>\n      <td>271.006011</td>\n      <td>285.958116</td>\n      <td>181.249410</td>\n      <td>9.835213e-08</td>\n      <td>12.0</td>\n      <td>0.947712</td>\n      <td>0.942483</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albania</td>\n      <td>country continent  year  lifeExp      pop ...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term    estimate    std_err  statistic...</td>\n      <td>country continent  year  lifeExp      pop ...</td>\n      <td>52.298071</td>\n      <td>53.267884</td>\n      <td>400.445959</td>\n      <td>439.771289</td>\n      <td>101.829014</td>\n      <td>1.462763e-06</td>\n      <td>12.0</td>\n      <td>0.910578</td>\n      <td>0.901636</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Algeria</td>\n      <td>country continent  year  lifeExp       pop...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term    estimate    std_err  statistic...</td>\n      <td>country continent  year  lifeExp       pop...</td>\n      <td>42.584427</td>\n      <td>43.554240</td>\n      <td>1158.583855</td>\n      <td>1176.087314</td>\n      <td>661.917086</td>\n      <td>1.808143e-10</td>\n      <td>12.0</td>\n      <td>0.985117</td>\n      <td>0.983629</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Angola</td>\n      <td>country continent  year  lifeExp       pop ...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term    estimate    std_err  statistic...</td>\n      <td>country continent  year  lifeExp       pop ...</td>\n      <td>44.061857</td>\n      <td>45.031670</td>\n      <td>156.667858</td>\n      <td>176.464605</td>\n      <td>79.138182</td>\n      <td>4.593498e-06</td>\n      <td>12.0</td>\n      <td>0.887815</td>\n      <td>0.876596</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Argentina</td>\n      <td>country continent  year  lifeExp       p...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term    estimate   std_err  statistic ...</td>\n      <td>country continent  year  lifeExp       p...</td>\n      <td>6.347866</td>\n      <td>7.317679</td>\n      <td>191.937384</td>\n      <td>192.791819</td>\n      <td>2246.366349</td>\n      <td>4.215567e-13</td>\n      <td>12.0</td>\n      <td>0.995568</td>\n      <td>0.995125</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>137</th>\n      <td>Vietnam</td>\n      <td>country continent  year  lifeExp       p...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term     estimate    std_err  statisti...</td>\n      <td>country continent  year  lifeExp       p...</td>\n      <td>42.414079</td>\n      <td>43.383892</td>\n      <td>1612.565329</td>\n      <td>1629.822069</td>\n      <td>934.455357</td>\n      <td>3.289412e-11</td>\n      <td>12.0</td>\n      <td>0.989412</td>\n      <td>0.988353</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>West Bank and Gaza</td>\n      <td>country continent  year  life...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term     estimate    std_err  statisti...</td>\n      <td>country continent  year  life...</td>\n      <td>52.287427</td>\n      <td>53.257240</td>\n      <td>1291.726331</td>\n      <td>1331.016795</td>\n      <td>328.763323</td>\n      <td>5.585089e-09</td>\n      <td>12.0</td>\n      <td>0.970481</td>\n      <td>0.967529</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>Yemen, Rep.</td>\n      <td>country continent  year  lifeExp    ...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term     estimate    std_err  statisti...</td>\n      <td>country continent  year  lifeExp    ...</td>\n      <td>46.932773</td>\n      <td>47.902586</td>\n      <td>1310.527555</td>\n      <td>1335.675109</td>\n      <td>521.135193</td>\n      <td>5.868274e-10</td>\n      <td>12.0</td>\n      <td>0.981172</td>\n      <td>0.979290</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>Zambia</td>\n      <td>country continent  year  lifeExp       po...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term    estimate     std_err  statisti...</td>\n      <td>country continent  year  lifeExp       po...</td>\n      <td>72.117172</td>\n      <td>73.086985</td>\n      <td>13.053046</td>\n      <td>218.145441</td>\n      <td>0.636447</td>\n      <td>4.435318e-01</td>\n      <td>12.0</td>\n      <td>0.059836</td>\n      <td>-0.034180</td>\n    </tr>\n    <tr>\n      <th>141</th>\n      <td>Zimbabwe</td>\n      <td>country continent  year  lifeExp       ...</td>\n      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n      <td>term    estimate     std_err  statisti...</td>\n      <td>country continent  year  lifeExp       ...</td>\n      <td>83.262706</td>\n      <td>84.232520</td>\n      <td>30.934127</td>\n      <td>550.116442</td>\n      <td>0.595824</td>\n      <td>4.580290e-01</td>\n      <td>12.0</td>\n      <td>0.056232</td>\n      <td>-0.038145</td>\n    </tr>\n  </tbody>\n</table>\n<p>142 rows × 14 columns</p>\n</div>\n```\n:::\n:::\n\n\nNow we could ask a question like \"what countries seem to have the most linear trends in life expectancy?\" and use R-squared as a measure of this.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\np = (\n    sns.FacetGrid(\n        data=glance_results.sort_values('rsquared'),\n        height=8,\n        aspect=16/9\n    )\n    .map(plt.scatter, 'rsquared', 'country')\n)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-1.png){width=1354 height=756}\n:::\n:::\n\n\nOkay so this plot is awful but I don't have the patience at the moment to make it better. We could also look at residuals for individual fits to inspect them for any patterns that might indicate systematic error.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\naugment_results = unnest(models, 'augmented')\n\np = (\n    sns.FacetGrid(\n        data=augment_results,\n        col='continent', \n        col_wrap=2,\n        hue='continent',\n        height=5, aspect=16/9)\n    .map(plt.plot, 'year', 'resid')\n)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-16-output-1.png){width=1696 height=1427}\n:::\n:::\n\n\nIt would be nice to add smooths by continent as Hadley does but again I don't have the patience or masochistic urge to figure out how to do that. In any case, there are some clear trends in the residuals, especially for Africa, which suggest that some further modeling is a good idea.\n\n## The end\n\nSo that's the basic idea behind the many models workflow. Note that we've been working at a fairly low-level of abstraction. This means you have a lot of control over what happens (good for research and EDA), but have to write a lot of code. If you're just fitting prediction models and the only thing you want to do is compare risk estimates, you can save time and effort by using `sklearn`'s `GridSearchCV` object.\n\nOne final note: in Hadley's gapminder example we iterate over disjoint data sets. In practice I do this extremely rarely. Much more often I find myself iterating over `(train, test)` pairs, or hyperparameters, or both at once. This hyperparameter optimization over many CV-folds workflow is more complex than the simple example here, but still fits nicely into the many models workflow I've described here. I'll demonstrate how to do that in a followup post.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}